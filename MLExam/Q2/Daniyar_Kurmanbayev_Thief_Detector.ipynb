{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thief Detector\n",
    "## This task tests your Image Processing skills to build a motion detection algorithm that alarms you when you have an unwanted visitor in your home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- 1. Get the live video feed from your webcam\n",
    "- 2. Fix a scene (the place you want to monitor) and store it as a reference background image\n",
    "    - Store the first frame as the reference background frame\n",
    "- 3. For every frame, check if there is any unwanted object inside the scene you are monitoring\n",
    "    - Use **Background Subtraction** concept (**cv2.absdiff( )**)\n",
    "        - Subtract the current frame from the reference background image(frame) to see the changes in the scene\n",
    "        - If there is enormous amount of pixels distrubed in the subtraction result image\n",
    "            - unwanted visitor (place is unsafe --> alarm the authorities)\n",
    "        - If there is no enormous amount of pixels distrubed in the subtraction result image\n",
    "            - no unwanted visitor (place is safe)\n",
    "- 4. Output the text **\"UNSAFE\"** in **red** color on the top right of the frame when there is an intruder in the scene.\n",
    "- 5. Save the live feed\n",
    "- 6. Submit the (.ipynb) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    cv2.imshow('Test', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get live video feed from webcam [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read first frame, convert to Grayscale and store it as reference background image [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, first_frame_original = capture.read()\n",
    "first_frame = cv2.cvtColor(first_frame_original, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Absolute Difference between Current and First frame [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, second_frame_original = capture.read()\n",
    "second_frame = cv2.cvtColor(second_frame_original, cv2.COLOR_BGR2GRAY)\n",
    "difference = cv2.absdiff(first_frame, second_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "show_image(difference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply threshold [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def thresh_otsu(image):\n",
    "    T_otsu = mahotas.thresholding.otsu(image)\n",
    "    thresh_otsu = image.copy()\n",
    "    thresh_otsu[thresh_otsu > T_otsu] = 255\n",
    "    thresh_otsu[thresh_otsu < 255] = 0\n",
    "    return cv2.bitwise_not(thresh_otsu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(difference, (5, 5), 0)\n",
    "thresh = thresh_otsu(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "show_image(thresh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find contours [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(thresh, 30, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "show_image(edged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if contourArea is large and draw rectangle around the object, output \"UNSAFE\" text in red color [30 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_test = second_frame.copy()\n",
    "cv2.drawContours(second_test, contours, -1, (0, 255, 0), 2)\n",
    "show_image(second_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_contours = [contour for contour in contours if cv2.contourArea(contour) > 500]\n",
    "len(large_contours)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[714, 627]], dtype=int32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_contours[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "second_test = second_frame_original.copy()\n",
    "for contour in large_contours:\n",
    "    x1 = 10000000\n",
    "    y1 = 10000000\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "\n",
    "    for coord in contour:\n",
    "        x = coord[0][0]\n",
    "        y = coord[0][1]\n",
    "        if x < x1:\n",
    "            x1 = x\n",
    "        if x > x2:\n",
    "            x2 = x\n",
    "        if y < y1:\n",
    "            y1 = y\n",
    "        if y > y2:\n",
    "            y2 = y\n",
    "\n",
    "    cv2.rectangle(second_test, (x1, y1), (x2, y2),(255, 255, 0), 2)\n",
    "\n",
    "show_image(second_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display images [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "video_writer = cv2.VideoWriter('Daniyar_Kurmanbayev_Exam_Q2.mp4', fourcc, 30, (int(width), int(height)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "_, background = capture.read()\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/1b/216kmv2s3731399_bt742lgw0000gn/T/ipykernel_10937/155133636.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcapture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mgray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCOLOR_BGR2GRAY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mdifference\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabsdiff\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbackground_gray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mblurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGaussianBlur\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdifference\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    _, frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    difference = cv2.absdiff(background_gray, gray)\n",
    "    blurred = cv2.GaussianBlur(difference, (5, 5), 0)\n",
    "    thresh = thresh_otsu(blurred)\n",
    "    edged = cv2.Canny(thresh, 30, 150)\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "\n",
    "    for contour in large_contours:\n",
    "        x1 = 10000000\n",
    "        y1 = 10000000\n",
    "        x2 = 0\n",
    "        y2 = 0\n",
    "\n",
    "        for coord in contour:\n",
    "            x = coord[0][0]\n",
    "            y = coord[0][1]\n",
    "            if x < x1:\n",
    "                x1 = x\n",
    "            if x > x2:\n",
    "                x2 = x\n",
    "            if y < y1:\n",
    "                y1 = y\n",
    "            if y > y2:\n",
    "                y2 = y\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2),(255, 255, 0), 2)\n",
    "    cv2.putText(img=frame,\n",
    "                    text='SAFE' if len(large_contours) == 0 else 'UNSAFE',\n",
    "                    org=(frame.shape[1] - 300, 100),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=2,\n",
    "                    color=(0, 0, 255),\n",
    "                    thickness=3,\n",
    "                    lineType=2)\n",
    "\n",
    "    video_writer.write(frame)\n",
    "\n",
    "    cv2.imshow(\"Motion detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release objects [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Everything in one class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas\n",
    "import time\n",
    "\n",
    "class ThiefDetector:\n",
    "    recording_fps = 30\n",
    "\n",
    "    __video_capture = None\n",
    "    __scale = 1\n",
    "    __video_writer = None\n",
    "\n",
    "    def __get_contours(self, frame, backround):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        difference = cv2.absdiff(backround, gray)\n",
    "        blurred = cv2.GaussianBlur(difference, (5, 5), 0)\n",
    "        thresh = thresh_otsu(blurred)\n",
    "        edged = cv2.Canny(thresh, 30, 150)\n",
    "        contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)\n",
    "        return contours\n",
    "\n",
    "    def __get_contour_coordinates(self, contour):\n",
    "        x1 = 10000000\n",
    "        y1 = 10000000\n",
    "        x2 = 0\n",
    "        y2 = 0\n",
    "\n",
    "        for coord in contour:\n",
    "            x = coord[0][0]\n",
    "            y = coord[0][1]\n",
    "            if x < x1:\n",
    "                x1 = x\n",
    "            if x > x2:\n",
    "                x2 = x\n",
    "            if y < y1:\n",
    "                y1 = y\n",
    "            if y > y2:\n",
    "                y2 = y\n",
    "\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    def __put_text(self, frame, is_safe):\n",
    "        cv2.putText(img=frame,\n",
    "                    text='SAFE' if is_safe else 'UNSAFE',\n",
    "                    org=(frame.shape[1] - 300, 100),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=2,\n",
    "                    color=(0, 0, 255),\n",
    "                    thickness=3,\n",
    "                    lineType=2)\n",
    "\n",
    "    def __record(self, background):\n",
    "        while self.__video_capture.isOpened():\n",
    "            _, frame = self.__video_capture.read()\n",
    "            contours = self.__get_contours(frame, background)\n",
    "            large_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "\n",
    "            for contour in large_contours:\n",
    "                x1, y1, x2, y2 = self.__get_contour_coordinates(contour)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2),(255, 255, 0), 2)\n",
    "\n",
    "            self.__put_text(frame, len(large_contours) == 0)\n",
    "\n",
    "            self.__video_writer.write(frame)\n",
    "\n",
    "            cv2.imshow(\"Motion detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.__video_capture.release()\n",
    "                self.__video_writer.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def start(self):\n",
    "        self.__video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "        width = self.__video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = self.__video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "        self.__video_writer = cv2.VideoWriter('Daniyar_Kurmanbayev_Exam_Q2.mp4', fourcc, 30, (int(width), int(height)))\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        _, background = self.__video_capture.read()\n",
    "        background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        self.__record(background_gray)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "thief_detector = ThiefDetector()\n",
    "thief_detector.start()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
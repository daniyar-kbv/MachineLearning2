{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulations\n",
    "## This notebook outlines the different techniques used on images using OpenCV library\n",
    "\n",
    "**Image Manipulations**\n",
    "- Cropping an image\n",
    "- Flipping an image\n",
    "- Masking an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image\n",
    "#### imread( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[139, 154, 173],\n        [142, 157, 176],\n        [142, 157, 176],\n        ...,\n        [158, 179, 200],\n        [156, 177, 198],\n        [154, 175, 196]],\n\n       [[135, 150, 169],\n        [139, 154, 173],\n        [139, 154, 173],\n        ...,\n        [158, 179, 200],\n        [157, 178, 199],\n        [156, 177, 198]],\n\n       [[136, 151, 170],\n        [142, 157, 176],\n        [141, 156, 175],\n        ...,\n        [158, 179, 200],\n        [159, 180, 201],\n        [160, 181, 202]],\n\n       ...,\n\n       [[133, 147, 169],\n        [132, 146, 168],\n        [129, 146, 167],\n        ...,\n        [134, 152, 175],\n        [133, 151, 174],\n        [133, 151, 174]],\n\n       [[132, 146, 168],\n        [131, 145, 167],\n        [128, 145, 166],\n        ...,\n        [135, 153, 176],\n        [135, 153, 176],\n        [134, 152, 175]],\n\n       [[132, 146, 168],\n        [131, 145, 167],\n        [128, 145, 166],\n        ...,\n        [133, 151, 174],\n        [133, 151, 174],\n        [130, 148, 171]]], dtype=uint8)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your favorite image and display it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"image.jpg\")\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping an image\n",
    "\n",
    "Cropping removes the outer parts of the image that we are not interested in.\n",
    "\n",
    "Cropping an image is as simple as using **array slices** in NumPy! \n",
    "\n",
    "Let's crop out the **face of the T-Rex**. \n",
    "\n",
    "\n",
    "We are supplying NumPy array slices to extract a rectangular region of the image, starting at (240, 30) and ending at (335,120). The order in which we supply the indexes to the crop may seem counterintuitive; however, remember that OpenCV represents images as NumPy arrays with the the height first and the width second. This means that we need to supply our y-axis values before our x-axis.\n",
    "\n",
    "The order in which we specify the coordinates is:\n",
    "- startY:endY\n",
    "- startX:endX\n",
    "\n",
    "In this case, we are \n",
    "- starting at Y=?? and ending at Y=??\n",
    "- start at X=?? and end at X=??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped = image[30:120 , 240:335]\n",
    "cv2.imshow(\"T-Rex Face\", cropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipping an image\n",
    "- Horizontal\n",
    "- Vertical\n",
    "- Both Axes\n",
    "\n",
    "The **cv2.flip method** requires two arguments\n",
    "- the **image** we want to flip\n",
    "- **flip code** that is used to determine how we are going to flip the image\n",
    "    - 1 --> horizontal flipping (y-axis)\n",
    "    - 0 --> vertical (x-axis)\n",
    "    - -1 --> both axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip the image horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped = cv2.flip(image, 1)\n",
    "cv2.imshow(\"Flipped Horizontally\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip the image vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped = cv2.flip(image, 0)\n",
    "cv2.imshow(\"Flipped Vertically\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip the image along both axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped = cv2.flip(image, -1)\n",
    "cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking an image\n",
    "Using a mask allows us to focus only on the portions of the image that **interests** us\n",
    "\n",
    "For example, let’s say that we were building a computer vision system to recognize faces. The only part of the image we are interested in finding and describing are the parts of the image that contain **faces** – we simply don’t care about the rest of the content of the image. \n",
    "\n",
    "Assuming that we could find the faces in the image, we might construct a mask to show only the faces in the image and not the unwanted rest of the parts of the image\n",
    "\n",
    "\n",
    "A mask is the same size as our image, but has only two pixel values, 0 and 255\n",
    "- Mask Pixels with a value of **0** are **ignored** in the orignal image\n",
    "- Mask Pixels with a value of **255** are **allowed** to be kept\n",
    "\n",
    "For example, let's construct a mask with a **150x150 square** at the center of it and mask our image\n",
    "\n",
    "#### Steps\n",
    "- Construct a NumPy array filled with **zeros** as same as the input image\n",
    "- Draw a **rectangle**\n",
    "- Apply **bitwise_and**\n",
    "- Display the mask applied to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a Zeros NumPy array with the same size of the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(480, 640)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "(cX, cY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(mask[0,0])\n",
    "print(mask[cY, cX])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"NewMask\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the bitwise_and\n",
    "- image\n",
    "- image\n",
    "- mask\n",
    "\n",
    "By supplying a mask, the cv2.bitwise_and function only examines pixels that are **“on”** in the mask. In this case, only pixels that are part of the white rectangle and omits all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = cv2.bitwise_and(image, image, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Mask Applied to Image\", masked)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract just the face of the T-rex using your custom mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "cv2.rectangle(mask, (225, 25), (325 , 125), 255, -1)\n",
    "masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "cv2.imshow(\"Mask Applied to Image\", masked)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a circular mask instead of a rectangular mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "cv2.circle(mask, (cX, cY), 100, 255, -1)\n",
    "masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Mask Applied to Image\", masked)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: Take an 007 Bond image and do a circular mask around him just for fun\n",
    "- Load the image\n",
    "- Display the image\n",
    "- Note the coordinates for correct positioning\n",
    "- Create a Circular Mask with the coordinates\n",
    "- Apply the mask\n",
    "- Display the masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
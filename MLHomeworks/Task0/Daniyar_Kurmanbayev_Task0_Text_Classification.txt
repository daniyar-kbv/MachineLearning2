I tried my best, but unfortunately I couldn't make Word2Vec work. Also had a problem with Doc2Vec and MultinomialNB.

Best combination:
CountVectorizer & MultinomialNB
score: 0.8824561403508772
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (2, 3),
    'feature_extractor__decode_error': 'strict',
    'feature_extractor__analyzer': 'word',
    'classifier__fit_prior': True,
    'classifier__alpha': 0.0
}

All variations:
1. CountVectorizer & MultinomialNB
score: 0.8824561403508772
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (2, 3),
    'feature_extractor__decode_error': 'strict',
    'feature_extractor__analyzer': 'word',
    'classifier__fit_prior': True,
    'classifier__alpha': 0.0
}
2. CountVectorizer & LogisticRegression
score: 0.8105263157894737
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 1),
    'feature_extractor__decode_error': 'strict',
    'feature_extractor__analyzer': 'word',
    'classifier__solver': 'lbfgs',
    'classifier__random_state': 42,
    'classifier__penalty': 'none',
    'classifier__multi_class': 'multinomial',
    'classifier__dual': False,
    'classifier__class_weight': 'balanced',
    'classifier__C': 0.0
}
3. CountVectorizer & SVC
score: 0.7473684210526316
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 2),
    'feature_extractor__decode_error': 'ignore',
    'feature_extractor__analyzer': 'word',
    'classifier__kernel': 'poly',
    'classifier__gamma': 0.75025,
    'classifier__C': 50.050000000000004
}
4. CountVectorizer & RandomForestClassifier
score: 0.8263157894736842
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 1),
    'feature_extractor__decode_error': 'replace',
    'feature_extractor__analyzer': 'word',
    'classifier__random_state': 42,
    'classifier__n_estimators': 150,
    'classifier__min_samples_split': 10,
    'classifier__min_samples_leaf': 1,
    'classifier__max_features': 'auto',
    'classifier__max_depth': None,
    'classifier__bootstrap': True
}
5. TfidfVectorizer & MultinomialNB
score: 0.8543859649122807
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 2),
    'feature_extractor__decode_error': 'ignore',
    'feature_extractor__analyzer': 'word',
    'classifier__fit_prior': True,
    'classifier__alpha': 0.0
}
6. TfidfVectorizer & LogisticRegression
score: 0.843859649122807
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 1),
    'feature_extractor__decode_error': 'strict',
    'feature_extractor__analyzer': 'word',
    'classifier__solver': 'lbfgs',
    'classifier__random_state': 42,
    'classifier__penalty': 'none',
    'classifier__multi_class': 'multinomial',
    'classifier__dual': False,
    'classifier__class_weight': 'balanced',
    'classifier__C': 0.0
}
7. TfidfVectorizer & SVC
score: 0.868421052631579
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 2),
    'feature_extractor__decode_error': 'strict',
    'feature_extractor__analyzer': 'word',
    'classifier__kernel': 'rbf',
    'classifier__gamma': 0.75025,
    'classifier__C': 75.025
}
8. TfidfVectorizer & RandomForestClassifier
score: 0.8298245614035088
{
    'feature_extractor__strip_accents': 'unicode',
    'feature_extractor__ngram_range': (1, 1),
    'feature_extractor__decode_error': 'replace',
    'feature_extractor__analyzer': 'word',
    'classifier__random_state': 42,
    'classifier__n_estimators': 100,
    'classifier__min_samples_split': 5,
    'classifier__min_samples_leaf': 1,
    'classifier__max_features': 'auto',
    'classifier__max_depth': None,
    'classifier__bootstrap': False
}
9. Doc2VecVectorizer & LogisticRegression
score: 0.6631578947368421
{
    'feature_extractor__window': 10,
    'feature_extractor__vector_size': 50,
    'feature_extractor__alpha': 0.275,
    'classifier__solver': 'lbfgs',
    'classifier__random_state': 42,
    'classifier__penalty': 'l2',
    'classifier__multi_class': 'auto',
    'classifier__dual': False,
    'classifier__class_weight': None,
    'classifier__C': 1.0
}
10. Doc2VecVectorizer & SVC
score: 0.612280701754386
{
    'feature_extractor__window': 10,
    'feature_extractor__vector_size': 50,
    'feature_extractor__alpha': 0.275,
    'classifier__kernel': 'poly',
    'classifier__gamma': 0.75025,
    'classifier__C': 0.1
}
11. Doc2VecVectorizer & RandomForestClassifier
score: 0.712280701754386
{
    'feature_extractor__window': 6,
    'feature_extractor__vector_size': 50,
    'feature_extractor__alpha': 0.2,
    'classifier__random_state': 42,
    'classifier__n_estimators': 300,
    'classifier__min_samples_split': 5,
    'classifier__min_samples_leaf': 4,
    'classifier__max_features': 'auto',
    'classifier__max_depth': 200.0,
    'classifier__bootstrap': False
}